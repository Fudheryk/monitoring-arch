# =============================================================================
# Docker Compose - DEV avec Traefik
# =============================================================================
# Services: db, redis, migrate, api, worker, beat, web, traefik, flaky, mailhog, status
#
# CHANGEMENTS vs Nginx:
# - Traefik remplace nginx comme reverse proxy
# - Certificats auto-signés gérés par Traefik (mkcert-like)
# - Auto-découverte services via labels Docker
# - Dashboard Traefik sur :8080
# - Segmentation réseau: frontend (public) + backend (privé)
# =============================================================================

x-app-common: &app-common
  build:
    context: ..
    dockerfile: ./server/Dockerfile.dev
  env_file: ../.env.docker
  working_dir: /app/server
  volumes:
    - ../server:/app/server:cached
  restart: unless-stopped
  security_opt:
    - no-new-privileges:true

services:
  # ---------------------------------------------------------------------------
  # Migrations (one-shot)
  # ---------------------------------------------------------------------------
  migrate:
    <<: *app-common
    container_name: monitoring-migrate-dev
    command: ["alembic", "upgrade", "head"]
    healthcheck:
      disable: true
    environment:
      DATABASE_URL: "postgresql+psycopg://postgres:${DB_PASSWORD}@db:5432/monitoring"
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
    depends_on:
      db:
        condition: service_healthy
    restart: "no"
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 512M

  # ---------------------------------------------------------------------------
  # API Backend
  # ---------------------------------------------------------------------------
  api:
    <<: *app-common
    container_name: monitoring-api-dev
    command: ["api"]
    environment:
      DATABASE_URL: "postgresql+psycopg://postgres:${DB_PASSWORD}@db:5432/monitoring"
      REDIS_URL: "${REDIS_URL:-redis://redis:6379/0}"
      STUB_SLACK: "1"
      DEFAULT_ALERT_REMINDER_MINUTES: "30"
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
      CORS_ALLOW_ORIGINS: "https://monitoring.local"
      LOG_LEVEL: "DEBUG"
      PROXY_HEADERS: "1"
      FORWARDED_ALLOW_IPS: "127.0.0.1,172.20.0.0/16,172.21.0.0/16"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    stop_signal: SIGINT
    stop_grace_period: 20s
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://127.0.0.1:8000/api/v1/health')\""]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 20s
    networks:
      - backend
    labels:
      # Traefik activation
      - "traefik.enable=true"
      - "traefik.docker.network=monitoring-dev_backend"
      
      # Router HTTP pour /api/*
      - "traefik.http.routers.api-dev.rule=Host(`monitoring.local`) && PathPrefix(`/api`)"
      - "traefik.http.routers.api-dev.entrypoints=websecure"
      - "traefik.http.routers.api-dev.tls=true"
      - "traefik.http.routers.api-dev.service=api-dev"
      - "traefik.http.services.api-dev.loadbalancer.server.port=8000"
      
      # Rate limiting sur /api/v1/ingest/*
      - "traefik.http.middlewares.api-ratelimit.ratelimit.average=10"
      - "traefik.http.middlewares.api-ratelimit.ratelimit.burst=20"
      - "traefik.http.middlewares.api-ratelimit.ratelimit.period=1s"
      - "traefik.http.routers.api-dev.middlewares=api-ratelimit@docker"
    deploy:
      resources:
        limits:
          memory: 1g

  # ---------------------------------------------------------------------------
  # Celery Worker
  # ---------------------------------------------------------------------------
  worker:
    <<: *app-common
    container_name: monitoring-worker-dev
    command: >
      sh -lc "
        celery -A app.workers.celery_app.celery worker
        -Q ingest,evaluate,heartbeat,http,notify,outbox
        --hostname=worker@%h
        -O fair -l debug
      "
    environment:
      DATABASE_URL: "postgresql+psycopg://postgres:${DB_PASSWORD}@db:5432/monitoring"
      REDIS_URL: "${REDIS_URL:-redis://redis:6379/0}"
      STUB_SLACK: "1"
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
      DEFAULT_ALERT_REMINDER_MINUTES: "30"
      LOG_LEVEL: "DEBUG"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    stop_grace_period: 60s
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.workers.celery_app.celery inspect ping --timeout=5 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 1g

  # ---------------------------------------------------------------------------
  # Celery Beat Scheduler
  # ---------------------------------------------------------------------------
  beat:
    <<: *app-common
    container_name: monitoring-beat-dev
    command: ["sh", "-lc", "celery -A app.workers.celery_app.celery beat -l debug --schedule /tmp/celerybeat-schedule --pidfile /tmp/celerybeat.pid"]
    environment:
      DATABASE_URL: "postgresql+psycopg://postgres:${DB_PASSWORD}@db:5432/monitoring"
      REDIS_URL: "${REDIS_URL:-redis://redis:6379/0}"
      STUB_SLACK: "1"
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
      DEFAULT_ALERT_REMINDER_MINUTES: "30"
      LOG_LEVEL: "DEBUG"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    stop_grace_period: 30s
    healthcheck:
      test: ["CMD-SHELL", "test -s /tmp/celerybeat.pid && pid=$$(cat /tmp/celerybeat.pid) && test -d /proc/$$pid"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 512M

  # ---------------------------------------------------------------------------
  # PostgreSQL Database
  # ---------------------------------------------------------------------------
  db:
    image: postgres:16
    container_name: monitoring-db-dev
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: monitoring
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d monitoring"]
      interval: 5s
      timeout: 5s
      retries: 10
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 1g
    security_opt:
      - no-new-privileges:true

  # ---------------------------------------------------------------------------
  # Redis
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7
    container_name: monitoring-redis-dev
    command: redis-server --save "" --appendonly no --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "sh", "-c", "redis-cli ping | grep -q PONG"]
      interval: 5s
      timeout: 3s
      retries: 10
    ports:
      - "6379:6379"
    restart: unless-stopped
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 512M
    security_opt:
      - no-new-privileges:true

  # ---------------------------------------------------------------------------
  # Web Frontend (SSR FastAPI)
  # ---------------------------------------------------------------------------
  web:
    build:
      context: ../webapp
      dockerfile: Dockerfile.dev
    container_name: monitoring-web-dev
    working_dir: /app/webapp
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "3000", "--reload"]
    environment:
      API_BASE_URL: "http://api:8000"
      LOGIN_PATH: "/login"
      PUBLIC_PATHS: "/login,/static,/_health,/health"
      LOG_LEVEL: "DEBUG"
    volumes:
      - ../webapp:/app/webapp:cached
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --timeout=3 -O /dev/null http://localhost:3000/_health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 15s
    restart: unless-stopped
    networks:
      - frontend
      - backend
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=monitoring-dev_frontend"
      
      # Router HTTP pour / (UI)
      - "traefik.http.routers.web-dev.rule=Host(`monitoring.local`)"
      - "traefik.http.routers.web-dev.entrypoints=websecure"
      - "traefik.http.routers.web-dev.tls=true"
      - "traefik.http.routers.web-dev.priority=1"
      - "traefik.http.routers.web-dev.service=web-dev"
      - "traefik.http.services.web-dev.loadbalancer.server.port=3000"
      
      # Rate limiting web
      - "traefik.http.middlewares.web-ratelimit.ratelimit.average=30"
      - "traefik.http.middlewares.web-ratelimit.ratelimit.burst=50"
      - "traefik.http.routers.web-dev.middlewares=web-ratelimit@docker"
    deploy:
      resources:
        limits:
          memory: 512M
    security_opt:
      - no-new-privileges:true

  # ---------------------------------------------------------------------------
  # Traefik Reverse Proxy
  # ---------------------------------------------------------------------------
  traefik:
    image: traefik:v3.2
    container_name: monitoring-traefik-dev
    command:
      # API et Dashboard
      - "--api.dashboard=true"
      - "--api.insecure=true"
      - "--ping=true"
      
      # Providers
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.network=monitoring-dev_frontend"
      
      # Entrypoints
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      
      # Redirection HTTP -> HTTPS
      - "--entrypoints.web.http.redirections.entrypoint.to=websecure"
      - "--entrypoints.web.http.redirections.entrypoint.scheme=https"
      
      # Certificats auto-signés pour dev
      - "--providers.file.filename=/traefik/dynamic.yml"
      
      # Logs
      - "--log.level=DEBUG"
      - "--accesslog=true"
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # Dashboard Traefik
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik-dev.yml:/traefik/dynamic.yml:ro
      - ./certs:/certs:ro
    restart: unless-stopped
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "traefik", "healthcheck", "--ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 128M
    security_opt:
      - no-new-privileges:true

  # ---------------------------------------------------------------------------
  # Service de test "flaky" (debug HTTP target)
  # ---------------------------------------------------------------------------
  flaky:
    build:
      context: ./flaky
      dockerfile: Dockerfile
    container_name: monitoring-flaky-dev
    ports:
      - "127.0.0.1:8081:80"
    restart: unless-stopped
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 128M

  # ---------------------------------------------------------------------------
  # MailHog (dev SMTP)
  # ---------------------------------------------------------------------------
  mailhog:
    image: mailhog/mailhog
    container_name: monitoring-mailhog-dev
    ports:
      - "1025:1025"
      - "8025:8025"
    restart: unless-stopped
    networks:
      - backend
    deploy:
      resources:
        limits:
          memory: 128M
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8025 || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  # ---------------------------------------------------------------------------
  # Monitoring Status Dashboard
  # ---------------------------------------------------------------------------
  status:
    build:
      context: ../status-dashboard
      dockerfile: Dockerfile
    container_name: monitoring-status-dev
    working_dir: /app
    volumes:
      - ../status-dashboard:/app:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: uvicorn app.main:app --host 0.0.0.0 --port 9100 --reload
    restart: unless-stopped
    networks:
      - frontend
      - backend
    security_opt:
      - no-new-privileges:true
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://127.0.0.1:9100/health')\""]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=monitoring-dev_frontend"
      
      # Router pour /status/*
      - "traefik.http.routers.status-dev.rule=Host(`monitoring.local`) && PathPrefix(`/status`)"
      - "traefik.http.routers.status-dev.entrypoints=websecure"
      - "traefik.http.routers.status-dev.tls=true"
      - "traefik.http.routers.status-dev.service=status-dev"
      - "traefik.http.services.status-dev.loadbalancer.server.port=9100"
      
      # Middleware pour strip /status prefix
      - "traefik.http.middlewares.status-strip.stripprefix.prefixes=/status"
      - "traefik.http.routers.status-dev.middlewares=status-strip@docker"

# =============================================================================
# Volumes
# =============================================================================
volumes:
  pg_data:
    driver: local

# =============================================================================
# Networks (segmentation)
# =============================================================================
networks:
  frontend:
    driver: bridge
    name: monitoring-dev_frontend
    ipam:
      config:
        - subnet: 172.20.0.0/16
  backend:
    driver: bridge
    name: monitoring-dev_backend
    ipam:
      config:
        - subnet: 172.21.0.0/16