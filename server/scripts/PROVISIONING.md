# PROVISIONING.md ‚Äî Provisioning client via INI (DEV & PROD)

## Objectif

Cr√©er automatiquement dans la base :

- **1 client**
- **1 admin** (email + r√¥le + mot de passe √©ventuellement g√©n√©r√©)
- **N API keys**
- des **settings client**
- des **HTTP targets**

Le provisioning est **idempotent** :  
‚û°Ô∏è relancer le script avec le m√™me INI **ne duplique pas** les donn√©es existantes.

---

## Fichiers importants

### INI (1 fichier par client)

üìå √Ä versionner dans Git :

`server/scripts/provisioning/<client>.ini`

Exemple :

`server/scripts/provisioning/smarthack.ini`

### Script

`server/scripts/provision_from_ini.py`

> ‚ö†Ô∏è Attention : selon l‚Äôenvironnement (DEV vs PROD), le chemin **dans le container** peut √™tre diff√©rent.  
> En DEV on a confirm√© :
>
> - script : `/app/server/scripts/provision_from_ini.py`
> - ini : `/app/server/scripts/provisioning/<client>.ini`

---

## S√©curit√© (anti-boulette)

Le script **refuse de s‚Äôex√©cuter** si tu ne mets pas explicitement :

`PROVISION_CLIENT=true`

Cela √©vite de cr√©er des clients ‚Äúpar erreur‚Äù en prod.

‚ö†Ô∏è Selon le code/config, en prod il peut aussi refuser si :

- `APP_ENV=production`
- et que `ALLOW_PROD_PROVISIONING=true` n‚Äôest pas fourni

---

## Workflow recommand√© (DEV ‚Üí PROD)

### 1) DEV : cr√©er/modifier le fichier INI

Sur ta machine dev :

```bash
cd /opt/monitoring-arch

nano server/scripts/provisioning/smarthack.ini
# ou cr√©er un nouveau fichier : server/scripts/provisioning/clientX.ini
````

Puis commit/push :

```bash
git add server/scripts/provisioning/smarthack.ini
git commit -m "chore(provisioning): add/update Smarthack client ini"
git push
```

---

### 2) PROD : r√©cup√©rer la derni√®re version (pull)

Sur la prod :

```bash
cd /opt/monitoring-arch
git pull
```

Ensuite tu dois retrouver le INI ici **sur l‚Äôh√¥te** :

```bash
ls -l server/scripts/provisioning/
```

‚ö†Ô∏è Note : m√™me si le fichier est sur l‚Äôh√¥te, le script doit √™tre ex√©cut√© **dans le container `api`**
(car lui a SQLAlchemy + acc√®s r√©seau DB via `db:5432`).

---

# Ex√©cution en PROD (la bonne m√©thode)

üìç Place-toi dans le dossier docker :

```bash
cd /opt/monitoring-arch/docker
```

Lancer le provisioning :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec \
  -e PROVISION_CLIENT=true api \
  sh -lc 'python /app/server/scripts/provision_from_ini.py /app/server/scripts/provisioning/smarthack.ini'
```

### R√©sultats attendus

* 1er run : cr√©e tout + g√©n√®re un fichier secrets si password admin vide
* runs suivants : **‚ÄúAucun secret g√©n√©r√©‚Äù** si tout existe d√©j√†

---

# Ex√©cution en DEV (Docker compose local)

üìç Place-toi dans le dossier docker :

```bash
cd /opt/monitoring-arch/docker
docker compose up -d
```

Lancer le provisioning :

```bash
docker compose exec -e PROVISION_CLIENT=true api \
  sh -lc 'python /app/server/scripts/provision_from_ini.py /app/server/scripts/provisioning/demo.ini'
```

> ‚úÖ En DEV, on a confirm√© que le script est ici :
> `/app/server/scripts/provision_from_ini.py`
> (et non `/app/server/server/scripts/...`)

---

# O√π sont les ‚Äúsecrets g√©n√©r√©s‚Äù ?

Si le mot de passe admin est laiss√© vide, le script √©crit un fichier du style :

`<ini>.generated.secrets.env`

Exemple (DEV ou PROD selon le container) :

`/app/server/scripts/provisioning/demo.ini.generated.secrets.env`

‚ö†Ô∏è Ce fichier est **dans le container**, pas sur l‚Äôh√¥te.

Lire le fichier (si besoin) :

```bash
docker compose exec api \
  sh -lc 'ls -l /app/server/scripts/provisioning/*.generated.secrets.env 2>/dev/null && echo "----" && cat /app/server/scripts/provisioning/*.generated.secrets.env || true'
```

Puis supprimer (recommand√©) :

```bash
docker compose exec api \
  sh -lc 'rm -f /app/server/scripts/provisioning/*.generated.secrets.env'
```

üìå IMPORTANT :

* **Ne jamais commit** ces fichiers
* **Ne pas les laisser tra√Æner** si tu veux limiter l‚Äôexposition

---

# V√©rifications apr√®s provisioning (audit acc√®s)

## V√©rifier les users (admin / actifs)

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select email,role,is_active,updated_at from users order by updated_at desc limit 50;\""
```

Pour un email pr√©cis :

```bash
EMAIL="client@exemple.com"

docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select email,role,is_active,updated_at from users where email='${EMAIL}';\""
```

---

## V√©rifier les API keys (cr√©√©es / actives / associ√©es √† une machine)

Lister les cl√©s :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select id,name,is_active,machine_id,last_used_at from api_keys order by name;\""
```

Lister les cl√©s **associ√©es √† une machine** (non ‚Äú√©tat initial‚Äù) :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select id,name,is_active,machine_id,last_used_at from api_keys where machine_id is not null order by name;\""
```

---

## V√©rifier les machines enregistr√©es (preuve d‚Äôune ingestion)

Pour un client donn√©, r√©cup√©rer son `client_id` (ex via une cl√© connue) :

```bash
CLIENT_ID="$(docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -Atc \"select distinct client_id from api_keys where name like 'smarthack-key-%' limit 1;\"")"
echo "CLIENT_ID=$CLIENT_ID"
```

Lister les machines du client :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select id,hostname,fingerprint,is_active,registered_at,last_seen from machines where client_id='${CLIENT_ID}' order by registered_at desc;\""
```

Attendu ‚Äú√©tat initial‚Äù : **0 row**

---

## V√©rifier les ingest_events (preuve d‚Äôingestions)

Compter :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select count(*) as ingest_count from ingest_events where client_id='${CLIENT_ID}';\""
```

D√©tail :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select created_at, ingest_id, machine_id, sent_at from ingest_events where client_id='${CLIENT_ID}' order by created_at desc limit 50;\""
```

Attendu ‚Äú√©tat initial‚Äù : `ingest_count = 0`

---

# Revenir √† un √©tat initial (reset client beta)

üéØ Objectif : repartir comme un client ‚Äúneuf‚Äù :

* aucune machine enregistr√©e
* aucune ingestion
* aucune association cl√© ‚Üî machine (`api_keys.machine_id = NULL`)
* reset `last_used_at`

‚ö†Ô∏è Attention : ces commandes suppriment des donn√©es runtime.

```bash
CLIENT_ID="***REDACTED_CLIENT_UUID***"

docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"
begin;

-- purge ingest
delete from ingest_events where client_id='${CLIENT_ID}';

-- purge machines (ON DELETE CASCADE => purge metric_instances/samples/alerts associ√©s si existants)
delete from machines where client_id='${CLIENT_ID}';

-- remettre last_used_at √† NULL
update api_keys set last_used_at=null where client_id='${CLIENT_ID}';

-- dissocier les cl√©s de toute machine
update api_keys set machine_id=null where client_id='${CLIENT_ID}';

commit;
\""
```

V√©rification post-reset :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"
select name,is_active,machine_id,last_used_at
from api_keys
where client_id='${CLIENT_ID}'
order by name;
\""

docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select count(*) as machines from machines where client_id='${CLIENT_ID}';\""

docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select count(*) as ingest_events from ingest_events where client_id='${CLIENT_ID}';\""
```

---

# R√©cup√©ration des cl√©s API (livrable client)

Afficher toutes les cl√©s + statut :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select name,key,is_active from api_keys where name like 'smarthack-key-%' order by name;\""
```

Export ‚Äúcl√© = valeur‚Äù :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -Atc \"select name || ' = ' || key from api_keys where name like 'smarthack-key-%' order by name;\""
```

> üîí Attention : ce genre d‚Äôexport doit √™tre fait **uniquement** pour livraison client, et **jamais logg√©** dans un terminal partag√©.

---

# Activer / d√©sactiver les cl√©s API

Activer toutes les cl√©s Smarthack :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"update api_keys set is_active=true where name like 'smarthack-key-%';\""
```

D√©sactiver toutes les cl√©s Smarthack :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"update api_keys set is_active=false where name like 'smarthack-key-%';\""
```

V√©rifier :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select name,is_active from api_keys where name like 'smarthack-key-%' order by name;\""
```

---

# Reset du mot de passe admin (cas user d√©j√† existant)

‚ö†Ô∏è Le provisioning est idempotent : si le user existe d√©j√†, il **ne modifie pas le mot de passe**.

Comme `users.password_hash` est hash√©, il est **impossible de r√©cup√©rer un password en clair** depuis la DB.

---

## ‚ö†Ô∏è Cas r√©el rencontr√© : hash tronqu√© ‚Üí login impossible

On a observ√© en prod un cas o√π :

* `users.password_hash` √©tait **tronqu√©** (ex: longueur 20)
* ce qui d√©clenchait :
  `passlib.exc.UnknownHashError: hash could not be identified`

‚û°Ô∏è Cause probable : update SQL mal √©chapp√© / mauvaise interpolation shell.

### V√©rifier l‚Äôint√©grit√© du hash

```bash
EMAIL="client@exemple.com"

docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -c \"select length(password_hash) as len, left(password_hash, 4) as prefix from users where email='${EMAIL}';\""
```

Attendu :

* `len ‚âà 60`
* `prefix = $2b$` (bcrypt)

---

## M√©thode safe (recommand√©e) : reset depuis le container `api`

üëâ Cette m√©thode utilise **le m√™me contexte bcrypt que l‚Äôapp**, donc aucun risque d‚Äôincompatibilit√©.

‚ö†Ô∏è **Correction s√©curit√©** (objectif "0 traces") :

* ne pas imprimer un mot de passe en clair dans les logs,
* g√©n√©rer le secret, mais ne l‚Äôafficher que si vous √™tes dans un canal s√©curis√©,
* id√©alement : √©crire le secret dans un fichier √©ph√©m√®re dans le container (puis le supprimer).

Exemple (ne print PAS le password) :

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec api sh -lc '
python - << "PY"
import os, secrets
from sqlalchemy import create_engine, text
from app.core.security import hash_password

EMAIL="client@exemple.com"

# G√©n√®re un password fort (ne pas l'afficher ici par d√©faut)
pwd = secrets.token_urlsafe(24)
h = hash_password(pwd)

db = os.getenv("DATABASE_URL") or os.getenv("SQLALCHEMY_DATABASE_URI")
engine = create_engine(db, future=True)

with engine.begin() as c:
    c.execute(
        text("update users set password_hash=:h, updated_at=now() where email=:e"),
        {"h": h, "e": EMAIL},
    )
    row = c.execute(
        text("select length(password_hash), left(password_hash,4) from users where email=:e"),
        {"e": EMAIL},
    ).fetchone()

print("HASH_LEN=", row[0])
print("HASH_PREFIX=", row[1])

# Si vous devez r√©cup√©rer le password, faites-le dans un canal s√©curis√© :
# print("NEW_PASSWORD=", pwd)
PY'
```

> üîê Recommandation : si tu dois afficher `NEW_PASSWORD`, fais-le **uniquement** en session priv√©e / canal s√©curis√©.

---

## V√©rifier que le password match bien en DB

```bash
docker compose --env-file ../.env.production -f docker-compose.prod.yml exec api sh -lc '
python - << "PY"
import os
from sqlalchemy import create_engine, text
from app.core.security import verify_password

EMAIL="client@exemple.com"
PWD="***REDACTED_CLEAR_PASSWORD***"

db = os.getenv("DATABASE_URL") or os.getenv("SQLALCHEMY_DATABASE_URI")
engine = create_engine(db, future=True)

with engine.begin() as c:
    h = c.execute(text("select password_hash from users where email=:e"), {"e": EMAIL}).scalar()

print("HASH_PREFIX=", h[:4])
print("HASH_LEN=", len(h))
print("VERIFY_AGAINST_DB=", verify_password(PWD, h))
PY'
```

---

# Tester le login API (DEV / PROD)

## En local (DEV)

‚ö†Ô∏è `http://127.0.0.1` redirige vers HTTPS (`301`), donc il faut soit :

### Option A ‚Äî appeler directement en HTTPS

```bash
curl -sk -i -X POST https://127.0.0.1/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"demo@dockl.com","password":"***REDACTED***"}' | head -n 30
```

### Option B ‚Äî suivre la redirection en conservant le body (curl)

```bash
curl -sk -i -L --post301 --post302 --post303 \
  -X POST http://127.0.0.1/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"demo@dockl.com","password":"***REDACTED***"}' | head -n 30
```

> üí° Sans `--post301`, `curl -L` peut perdre le body ‚Üí erreur `422 Unprocessable Entity`.

---

# Tester l‚Äôingest avec une cl√© API

R√©cup√©rer une cl√© en une ligne :

```bash
API_KEY="$(docker compose --env-file ../.env.production -f docker-compose.prod.yml exec -T db \
  sh -lc "psql -U postgres -d monitoring -Atc \"select key from api_keys where name='smarthack-key-01';\"")"
```

Test :

```bash
SENT_AT="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"

curl -sk -i -X POST https://neonmonitor.dockl.com/api/v1/ingest/metrics \
  -H "X-API-Key: $API_KEY" \
  -H "Content-Type: application/json" \
  -d "{\"sent_at\":\"$SENT_AT\",\"machine\":{\"hostname\":\"prod-test-01\",\"os\":\"Linux\",\"fingerprint\":\"prod-test-01\"},\"metrics\":[]}" \
| awk "NR==1 || /^\{/ {print}"
```

Attendu : `HTTP/2 202`

---

# Template ‚ÄúLivrable client b√™ta‚Äù (anonymis√©)

## Livrable client b√™ta ‚Äî <CLIENT_NAME>

### Acc√®s interface (compte admin)

* **URL** : `https://<DOMAIN>`
* **Email** : `<ADMIN_EMAIL>`
* **Mot de passe** : `***REDACTED***`
* **R√¥le** : `admin_client`

> Merci de changer le mot de passe d√®s la premi√®re connexion.

---

### Acc√®s API (ingestion)

* **Endpoint** : `POST https://<DOMAIN>/api/v1/ingest/metrics`
* **Header** : `X-API-Key: <API_KEY>`

#### Cl√© active (√† utiliser)

* `<key-name-01>` = `***REDACTED***`

#### Cl√©s de r√©serve (inactives)

* `<key-name-02>` = `***REDACTED***`
* `<key-name-03>` = `***REDACTED***`
* `<key-name-04>` = `***REDACTED***`

---

### Exemple de test ingestion (curl)

```bash
API_KEY="***REDACTED***"
SENT_AT="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"

curl -sk -i -X POST "https://<DOMAIN>/api/v1/ingest/metrics" \
  -H "X-API-Key: $API_KEY" \
  -H "Content-Type: application/json" \
  -d "{\"sent_at\":\"$SENT_AT\",\"machine\":{\"hostname\":\"client-test-01\",\"os\":\"Linux\",\"fingerprint\":\"client-test-01\"},\"metrics\":[]}" \
| awk "NR==1 || /^\{/ {print}"
```

**Attendu** : `HTTP/2 202`

> √Ä la premi√®re ingestion, la machine est enregistr√©e √† partir de `hostname` + `fingerprint`.



### EXECUTION 

docker exec -it monitoring-api sh -lc '
  set -e
  cd /app

  export PROVISION_CLIENT=true
  export DATABASE_URL="postgresql+psycopg://postgres:${DB_PASSWORD}@db:5432/monitoring"

  for f in server/scripts/provisioning/*.ini; do
    [ -f "$f" ] || continue
    echo "==> Provision: $f"
    python server/scripts/provision_from_ini.py "$f"
  done
'
