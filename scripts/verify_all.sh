#!/usr/bin/env bash
#  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# scripts/verify_all.sh
#  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# V√©rif globale :
#   1) Unit (host, SQLite) + coverage
#   2) Stack Docker up (db/redis/api/worker) + migrations Alembic
#   3) Integration (host, Postgres) + coverage append
#   4) E2E (host -> API) + coverage append
#   5) Stop api/worker (flush coverage) + combine (host + fragments containers)
#   6) Coverage report + xml
#
# Notes :
#   - PYTHONPATH=server pour que "app.*" soit importable
#   - L'override docker-compose.coverage.yml est toujours activ√© pour capturer
#     la couverture c√¥t√© API/worker (fragments √©crits sous ./server)
#
# Auth / s√©curit√© :
#   - /api/v1/health est PUBLIC ‚Üí aucun header d'auth ne doit √™tre envoy√©.
#   - La variable KEY (API key) est requise uniquement pour les endpoints ingest
#     (ex: POST /api/v1/ingest/metrics) et autres endpoints prot√©g√©s par API key.
#  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
set -euo pipefail

# --- Config -------------------------------------------------------------------
: "${API:=http://localhost:8000}"           # endpoint public de l'API (base URL)
: "${THRESHOLD:=70}"                        # seuil de couverture finale (report --fail-under)
: "${BUILD:=0}"                             # BUILD=1 pour docker compose --build
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

# --- Helpers ------------------------------------------------------------------
log() { printf "\n\033[1;34m[%s]\033[0m %s\n" "verify" "$*"; }

cleanup_coverage() {
  log "nettoyage fragments de coverage‚Ä¶"
  # fragments host (racine)
  find "$PROJECT_ROOT" -maxdepth 1 -type f -name ".coverage*" ! -name ".coveragerc" -print -delete || true
  # fragments containers (mont√©s dans ./server)
  find "$PROJECT_ROOT/server" -maxdepth 1 -type f -name ".coverage*" ! -name ".coveragerc" -print -delete || true
  rm -rf "$PROJECT_ROOT/htmlcov" || true
  rm -f  "$PROJECT_ROOT/coverage.xml" || true
}

# Attendre que l'API r√©ponde sur le healthcheck PUBLIC (sans header d'auth)
wait_api() {
  log "attente de l'API ($API/api/v1/health)‚Ä¶"
  for i in {1..60}; do
    if curl -fsS "$API/api/v1/health" >/dev/null 2>&1; then
      log "API ok."
      return 0
    fi
    sleep 2
  done
  log "‚ùå API indisponible apr√®s attente."
  return 1
}

# Guard explicite : KEY est requise uniquement si on appelle un endpoint prot√©g√© par API key
require_key() {
  : "${KEY:?Missing KEY env var (API key). Example: KEY=<API_KEY> ./scripts/verify_all.sh}"
}

# Wrapper docker compose (toujours avec l'override coverage)
dc() {
  # On ajoute syst√©matiquement le fichier coverage pour que l‚ÄôAPI/worker
  # √©mettent des fichiers .coverage.* dans ./server (volume partag√©).
  ( cd "$PROJECT_ROOT/docker" && docker compose \
      -f docker-compose.yml \
      -f docker-compose.coverage.yml \
      "$@" )
}

ensure_env_docker() {
  # Pr√©pare .env.docker √† la racine et copie dans docker/.env.docker.
  #
  # ‚ö†Ô∏è Objectif : rester "CI-like" et √©viter les surprises :
  # - On force un webhook Slack stub (httpbin) si absent
  # - On r√©duit ALERT_REMINDER_MINUTES pour acc√©l√©rer
  # - On active STUB_SLACK=1
  if [[ ! -f "$PROJECT_ROOT/.env.docker" ]]; then
    if [[ -f "$PROJECT_ROOT/.env.example" ]]; then
      cp "$PROJECT_ROOT/.env.example" "$PROJECT_ROOT/.env.docker"
    else
      echo "ERROR: .env.example introuvable √† la racine" >&2
      exit 1
    fi
    awk 'BEGIN{pslack=0; prem=0}
         /^SLACK_WEBHOOK=/ {print "SLACK_WEBHOOK=http://httpbin:80/status/204"; pslack=1; next}
         /^ALERT_REMINDER_MINUTES=/ {print "ALERT_REMINDER_MINUTES=1"; prem=1; next}
         {print}
         END{
           if(!pslack) print "SLACK_WEBHOOK=http://httpbin:80/status/204";
           if(!prem)   print "ALERT_REMINDER_MINUTES=1";
           print "STUB_SLACK=1";
         }' "$PROJECT_ROOT/.env.docker" > "$PROJECT_ROOT/.env.docker.tmp"
    mv "$PROJECT_ROOT/.env.docker.tmp" "$PROJECT_ROOT/.env.docker"
  fi
  cp "$PROJECT_ROOT/.env.docker" "$PROJECT_ROOT/docker/.env.docker"
}

dump_logs_on_error() {
  echo "‚îÄ‚îÄ‚îÄ‚îÄ docker compose ps";         (cd "$PROJECT_ROOT/docker" && docker compose ps) || true
  echo "‚îÄ‚îÄ‚îÄ‚îÄ api logs (tail 200)";      (cd "$PROJECT_ROOT/docker" && docker compose logs api    | tail -n 200) || true
  echo "‚îÄ‚îÄ‚îÄ‚îÄ worker logs (tail 200)";   (cd "$PROJECT_ROOT/docker" && docker compose logs worker | tail -n 200) || true
  echo "‚îÄ‚îÄ‚îÄ‚îÄ db logs (tail 120)";       (cd "$PROJECT_ROOT/docker" && docker compose logs db     | tail -n 120) || true
}

# --- Start --------------------------------------------------------------------
cd "$PROJECT_ROOT"

# 0) Venv "CI-like" + deps
log "pr√©pare venv .venv-ci + d√©pendances‚Ä¶"
python -m venv .venv-ci
# shellcheck disable=SC1091
source .venv-ci/bin/activate
python -m pip install -U pip
pip install -r requirements-dev.txt
# Requis pour INTEG/E2E (acc√®s Postgres c√¥t√© host)
pip install "psycopg[binary]>=3.1,<4.0"

export PYTHONPATH=server

# 0bis) Nettoyage coverage
cleanup_coverage

# 1) UNIT TESTS (host) -> .coverage.host
#    (ENV SQLite et Celery eager sont g√©r√©s par server/tests/unit/conftest.py)
log "pytest UNIT (host) + coverage ‚Üí .coverage.host"
COVERAGE_FILE=".coverage.host" \
pytest -m "unit" -n auto \
  --maxfail=1 \
  --cov=server/app --cov-report=term-missing --cov-config=.coveragerc --cov-branch \
  --cov-fail-under=60

# 2) STACK UP (db/redis/api/worker) + migrations (toujours avec override coverage)
log "docker compose up‚Ä¶"
ensure_env_docker
if [[ "$BUILD" == "1" ]]; then
  dc --env-file ../.env.docker up -d --build db redis api worker
else
  dc --env-file ../.env.docker up -d db redis api worker
fi

# Stopper proprement √† la fin quoi qu‚Äôil arrive
trap 'log "docker compose down -v"; dc --env-file ../.env.docker down -v || true' EXIT

# Wait DB ready
log "attente DB (pg_isready)‚Ä¶"
for i in {1..60}; do
  if dc --env-file ../.env.docker exec -T db pg_isready -U postgres >/dev/null 2>&1; then
    break
  fi
  sleep 2
done

# Migrations Alembic dans le conteneur API (chemins typiques de ton projet)
log "alembic upgrade head (dans le conteneur api)‚Ä¶"
if ! dc --env-file ../.env.docker run --rm -w /app/server api alembic -c /app/server/alembic.ini upgrade head; then
  echo "‚ùå Alembic upgrade failed"
  dump_logs_on_error
  exit 1
fi

# Wait API healthy (healthcheck PUBLIC)
wait_api

# 3) INTEGRATION TESTS (host)
#    (force host ‚Üí Postgres expos√© par Docker)
export DATABASE_URL="${DATABASE_URL:-postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5}"
log "DATABASE_URL (host) -> $DATABASE_URL"

log "pytest INTEGRATION (host) + coverage append"
COVERAGE_FILE=".coverage.host" \
pytest -m "integration" \
  --maxfail=1 \
  --cov=server/app --cov-report=term-missing --cov-config=.coveragerc --cov-branch \
  --cov-append --cov-fail-under=0

# 4) E2E TESTS (host ‚Üí containers)
# Si tes tests e2e appellent des endpoints ingest (API key),
# la variable KEY doit √™tre fournie par l'environnement.
log "pytest E2E (host ‚Üí API) + coverage append"
export E2E_STACK_UP=1
require_key

COVERAGE_FILE=".coverage.host" \
pytest -m "e2e" \
  --maxfail=1 \
  --cov=server/app --cov-report=term-missing --cov-config=.coveragerc --cov-branch \
  --cov-append --cov-fail-under=0

# ‚ö†Ô∏è IMPORTANT : stop API/worker pour *flusher* les fichiers coverage c√¥t√© containers
log "stop API/worker (flush coverage data)‚Ä¶"
dc --env-file ../.env.docker stop api || true
dc --env-file ../.env.docker stop worker || true

# 5) COMBINE COVERAGE (host + fragments containers)
log "combine coverage (host + containers)‚Ä¶"
files=""
test -s .coverage.host && files="$files .coverage.host"
# *tous* les fragments √©crits sous ./server par api/worker (volume partag√©)
api_worker_files="$(find server -maxdepth 1 -type f -name '.coverage*' ! -name '.coveragerc' -size +0c -printf ' %p' 2>/dev/null || true)"
files="$files$api_worker_files"

if [[ -z "${files// /}" ]]; then
  echo "‚ùå Aucun fichier coverage trouv√© √† combiner"
  echo "üìÇ Debug list:"
  ls -la . server || true
  exit 1
fi

log "‚è≥ Combine: $files"
COVERAGE_FILE=.coverage COVERAGE_RCFILE=.coveragerc python -m coverage combine -q $files
COVERAGE_FILE=.coverage COVERAGE_RCFILE=.coveragerc python -m coverage report -m --fail-under="$THRESHOLD"
COVERAGE_FILE=.coverage COVERAGE_RCFILE=.coveragerc python -m coverage xml -o coverage.xml

log "‚úÖ OK ‚Äî couverture ‚â• ${THRESHOLD}%"
