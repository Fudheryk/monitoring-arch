#!/usr/bin/env bash
#  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# V√©rif globale: unit -> (stack up) -> integration -> e2e -> combine coverage -> (stack down)
# - Cr√©e/active un venv "CI-like" (.venv-ci) et installe les deps (dont psycopg)
# - Force PYTHONPATH=server pour que "app.*" soit importable
# - Unit  : SQLite in-memory, coverage stricte (fail-under=60 ici, puis seuil global)
# - Integ/E2E : stack Docker (db/redis/api/worker), migrations Alembic, tests host
# - Combine : coverage host + fragments √©crits par les containers sous ./server
# - Utilise *toujours* l'override docker-compose.coverage.yml pour capturer la
#   couverture c√¥t√© API/worker.
#  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
set -euo pipefail

# --- Config -------------------------------------------------------------------
: "${API:=http://localhost:8000}"           # endpoint public de l'API
: "${KEY:=dev-apikey-123}"                  # API key par d√©faut
: "${THRESHOLD:=70}"                        # seuil de couverture finale (report --fail-under)
: "${BUILD:=0}"                             # BUILD=1 pour docker compose --build
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

# --- Helpers ------------------------------------------------------------------
log() { printf "\n\033[1;34m[%s]\033[0m %s\n" "verify" "$*"; }

cleanup_coverage() {
  log "nettoyage fragments de coverage‚Ä¶"
  # fragments host (racine)
  find "$PROJECT_ROOT" -maxdepth 1 -type f -name ".coverage*" ! -name ".coveragerc" -print -delete || true
  # fragments containers (mont√©s dans ./server)
  find "$PROJECT_ROOT/server" -maxdepth 1 -type f -name ".coverage*" ! -name ".coveragerc" -print -delete || true
  rm -rf "$PROJECT_ROOT/htmlcov" || true
  rm -f  "$PROJECT_ROOT/coverage.xml" || true
}

wait_api() {
  log "attente de l'API ($API/api/v1/health)‚Ä¶"
  for i in {1..60}; do
    if curl -fsS -H "X-API-Key: $KEY" "$API/api/v1/health" >/dev/null 2>&1; then
      log "API ok."
      return 0
    fi
    sleep 2
  done
  log "‚ùå API indisponible apr√®s attente."
  return 1
}

# Wrapper docker compose (toujours avec l'override coverage)
dc() {
  # on ajoute syst√©matiquement le fichier coverage pour que l‚ÄôAPI/worker
  #      √©mettent des fichiers .coverage.* dans ./server
  ( cd "$PROJECT_ROOT/docker" && docker compose \
      -f docker-compose.yml \
      -f docker-compose.coverage.yml \
      "$@" )
}

ensure_env_docker() {
  # pr√©pare .env.docker √† la racine et copie dans docker/.env.docker
  if [[ ! -f "$PROJECT_ROOT/.env.docker" ]]; then
    if [[ -f "$PROJECT_ROOT/.env.example" ]]; then
      cp "$PROJECT_ROOT/.env.example" "$PROJECT_ROOT/.env.docker"
    else
      echo "ERROR: .env.example introuvable √† la racine" >&2
      exit 1
    fi
    # impose quelques d√©fauts s√ªrs pour la CI/locale
    awk 'BEGIN{pslack=0; prem=0}
         /^SLACK_WEBHOOK=/ {print "SLACK_WEBHOOK=http://httpbin:80/status/204"; pslack=1; next}
         /^ALERT_REMINDER_MINUTES=/ {print "ALERT_REMINDER_MINUTES=1"; prem=1; next}
         {print}
         END{
           if(!pslack) print "SLACK_WEBHOOK=http://httpbin:80/status/204";
           if(!prem)   print "ALERT_REMINDER_MINUTES=1";
           print "STUB_SLACK=1";
         }' "$PROJECT_ROOT/.env.docker" > "$PROJECT_ROOT/.env.docker.tmp"
    mv "$PROJECT_ROOT/.env.docker.tmp" "$PROJECT_ROOT/.env.docker"
  fi
  cp "$PROJECT_ROOT/.env.docker" "$PROJECT_ROOT/docker/.env.docker"
}

dump_logs_on_error() {
  echo "‚îÄ‚îÄ‚îÄ‚îÄ docker compose ps";         (cd "$PROJECT_ROOT/docker" && docker compose ps) || true
  echo "‚îÄ‚îÄ‚îÄ‚îÄ api logs (tail 200)";      (cd "$PROJECT_ROOT/docker" && docker compose logs api    | tail -n 200) || true
  echo "‚îÄ‚îÄ‚îÄ‚îÄ worker logs (tail 200)";   (cd "$PROJECT_ROOT/docker" && docker compose logs worker | tail -n 200) || true
  echo "‚îÄ‚îÄ‚îÄ‚îÄ db logs (tail 120)";       (cd "$PROJECT_ROOT/docker" && docker compose logs db     | tail -n 120) || true
}

# --- Start --------------------------------------------------------------------
cd "$PROJECT_ROOT"

# 0) Venv "CI-like" + deps
log "pr√©pare venv .venv-ci + d√©pendances‚Ä¶"
python -m venv .venv-ci
# shellcheck disable=SC1091
source .venv-ci/bin/activate
python -m pip install -U pip
pip install -r requirements-dev.txt
# Requis pour INTEG/E2E (acc√®s Postgres c√¥t√© host)
pip install "psycopg[binary]>=3.1,<4.0"

export PYTHONPATH=server

# 0bis) Nettoyage coverage
cleanup_coverage

# 1) UNIT TESTS (host) -> .coverage.host
#    (ENV SQLite et Celery eager sont g√©r√©s par server/tests/unit/conftest.py)
log "pytest UNIT (host) + coverage ‚Üí .coverage.host"
COVERAGE_FILE=".coverage.host" \
pytest -m "unit" -n auto \
  --maxfail=1 \
  --cov=server/app --cov-report=term-missing --cov-config=.coveragerc --cov-branch \
  --cov-fail-under=60

# 2) STACK UP (db/redis/api/worker) + migrations (toujours avec override coverage)
log "docker compose up‚Ä¶"
ensure_env_docker
if [[ "$BUILD" == "1" ]]; then
  dc --env-file ../.env.docker up -d --build db redis api worker
else
  dc --env-file ../.env.docker up -d db redis api worker
fi

# Stopper proprement √† la fin quoi qu‚Äôil arrive
trap 'log "docker compose down -v"; dc --env-file ../.env.docker down -v || true' EXIT

# Wait DB ready
log "attente DB (pg_isready)‚Ä¶"
for i in {1..60}; do
  if dc --env-file ../.env.docker exec -T db pg_isready -U postgres >/dev/null 2>&1; then
    break
  fi
  sleep 2
done

# Migrations Alembic dans le conteneur API (chemins typiques de ton projet)
log "alembic upgrade head (dans le conteneur api)‚Ä¶"
if ! dc --env-file ../.env.docker run --rm -w /app/server api alembic -c /app/server/alembic.ini upgrade head; then
  echo "‚ùå Alembic upgrade failed"; dump_logs_on_error; exit 1
fi

# Wait API healthy (healthcheck)
wait_api

# 3) INTEGRATION TESTS (host)
#    (force host ‚Üí Postgres expos√© par Docker)
export DATABASE_URL="${DATABASE_URL:-postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5}"
log "DATABASE_URL (host) -> $DATABASE_URL"

log "pytest INTEGRATION (host) + coverage append"
COVERAGE_FILE=".coverage.host" \
pytest -m "integration" \
  --maxfail=1 \
  --cov=server/app --cov-report=term-missing --cov-config=.coveragerc --cov-branch \
  --cov-append --cov-fail-under=0

# 4) E2E TESTS (host ‚Üí containers)
log "pytest E2E (host ‚Üí API) + coverage append"
export E2E_STACK_UP=1
COVERAGE_FILE=".coverage.host" \
pytest -m "e2e" \
  --maxfail=1 \
  --cov=server/app --cov-report=term-missing --cov-config=.coveragerc --cov-branch \
  --cov-append --cov-fail-under=0

# ‚ö†Ô∏è IMPORTANT : stop API/worker pour *flusher* les fichiers coverage c√¥t√© containers
log "stop API/worker (flush coverage data)‚Ä¶"
dc --env-file ../.env.docker stop api || true
dc --env-file ../.env.docker stop worker || true

# 5) COMBINE COVERAGE (host + fragments containers)
log "combine coverage (host + containers)‚Ä¶"
files=""
test -s .coverage.host && files="$files .coverage.host"
# *tous* les fragments √©crits sous ./server par api/worker (volume partag√©)
api_worker_files="$(find server -maxdepth 1 -type f -name '.coverage*' ! -name '.coveragerc' -size +0c -printf ' %p' 2>/dev/null || true)"
files="$files$api_worker_files"

if [[ -z "${files// /}" ]]; then
  echo "‚ùå Aucun fichier coverage trouv√© √† combiner"
  echo "üìÇ Debug list:"
  ls -la . server || true
  exit 1
fi

log "‚è≥ Combine: $files"
COVERAGE_FILE=.coverage COVERAGE_RCFILE=.coveragerc python -m coverage combine -q $files
COVERAGE_FILE=.coverage COVERAGE_RCFILE=.coveragerc python -m coverage report -m --fail-under="$THRESHOLD"
COVERAGE_FILE=.coverage COVERAGE_RCFILE=.coveragerc python -m coverage xml -o coverage.xml

log "‚úÖ OK ‚Äî couverture ‚â• ${THRESHOLD}%"
