# CI en 3 étapes principales : unit → integration → e2e
# + 1 job "aggregate-unit-coverage" pour combiner la couverture des shards unit
# - Unit : parallélisé (matrix sharding x4 + xdist), DB SQLite in-memory
# - Integration / E2E : stack Docker, migrations Alembic, tests exécutés côté host
# - Pas d'upload Codecov (pas de compte requis). La couverture unit combinée est publiée en artifact.

name: CI

on:
  push:
    branches: [ main ]
  pull_request:

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  # ---------------------------------------------------------------------------
  # 1) UNIT — sans Docker, parallélisé par sharding (4 shards) + xdist
  # ---------------------------------------------------------------------------
  unit:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false         # ne stoppe pas les autres shards si un échoue
      matrix:
        shard: [1, 2, 3, 4]    # 4 shards équilibrés via pytest-split
    env:
      PYTHONPATH: server
      ENV_FILE: /dev/null
      DATABASE_URL: 'sqlite+pysqlite:///:memory:'
      REDIS_URL: redis://localhost:6379/0
      STUB_SLACK: "1"
      ALERT_REMINDER_MINUTES: "1"
      KEY: dev-apikey-123
      API: http://localhost:8000
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure curl + jq are present
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl jq

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install project deps (unit)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          # lib pour sharder proprement la suite (équilibrage par historique)
          pip install pytest-split

      # Debug après checkout et avec PYTHONPATH=server, comme demandé
      - name: Debug env & settings (after checkout)
        env:
          PYTHONPATH: server
        run: |
          echo "PYTHONPATH=${PYTHONPATH}"
          echo "ENV_FILE=${ENV_FILE}"
          echo "DATABASE_URL=${DATABASE_URL}"
          python - <<'PY'
          import os, sys
          print("ENV_FILE      =", os.getenv("ENV_FILE"))
          print("DATABASE_URL  =", os.getenv("DATABASE_URL"))
          print("sys.path[:3]  =", sys.path[:3])
          try:
              from app.core.config import settings
              print("settings.DATABASE_URL =", getattr(settings, "DATABASE_URL", None) or getattr(settings, "database_url", None))
          except Exception as e:
              print("Import settings FAILED:", e)
          PY

      # DIAGNOSTIC COMPLET AVANT LES TESTS
      - name: Pre-test diagnostics
        env:
          PYTHONPATH: server
        run: |
          echo "=== PRE-TEST DIAGNOSTICS ==="
          
          # 1. Vérifier pytest et plugins
          echo "1. Pytest version and plugins:"
          pytest --version
          pytest --help | grep -A5 -B5 "split\|cov" || echo "No split/cov options found"
          
          # 2. Test discovery
          echo ""
          echo "2. Test discovery (unit tests):"
          pytest --collect-only -m "unit" --quiet || echo "❌ Test collection failed"
          
          # 3. Vérifier pytest-split
          echo ""
          echo "3. Testing pytest-split installation:"
          python -c "import pytest_split; print('✓ pytest-split imported OK')" || echo "❌ pytest-split import failed"
          
          # 4. Dry-run du sharding
          echo ""
          echo "4. Dry-run sharding for shard ${{ matrix.shard }}:"
          pytest --collect-only -m "unit" --splits 4 --group ${{ matrix.shard }} -q 2>/dev/null || {
            echo "❌ pytest-split failed, will use alternative sharding"
            echo "Available test files:"
            find . -name "*test*.py" -path "*/tests/*" | head -10
          }
          
          # 5. Permissions et répertoire de travail
          echo ""
          echo "5. Directory permissions:"
          echo "Current dir: $(pwd)"
          echo "Write permissions: $(test -w . && echo "✓ OK" || echo "❌ NO")"
          touch .test_write && rm .test_write && echo "✓ Can create files" || echo "❌ Cannot create files"

      - name: Run unit tests (shard ${{ matrix.shard }})
        env:
          CELERY_TASK_ALWAYS_EAGER: "1"
          STUB_SLACK: "1"
          ALERT_REMINDER_MINUTES: "1"
          SLACK_WEBHOOK: "http://httpbin:80/status/204"
          PYTHONPATH: server
        run: |
          set -euo pipefail
          
          # Configuration de la couverture
          export COVERAGE_FILE=".coverage.unit.${{ matrix.shard }}"
          echo "=== RUNNING UNIT TESTS SHARD ${{ matrix.shard }} ==="
          echo "COVERAGE_FILE=$COVERAGE_FILE"
          echo "Working directory: $(pwd)"
          
          # Tentative avec pytest-split d'abord
          echo ""
          echo "Attempting pytest-split sharding..."
          if pytest -m "unit" --splits 4 --group ${{ matrix.shard }} -n auto \
            --cov=server/app --cov-config=.coveragerc \
            --cov-report=term-missing \
            --cov-fail-under=0 --maxfail=1; then
            
            echo "✓ pytest-split succeeded"
            TESTS_RAN=true
            
          else
            echo ""
            echo "❌ pytest-split failed, trying alternative sharding..."
            
            # Alternative : découpage manuel par nom de fichier
            mapfile -t TEST_FILES < <(find . -name "*test*.py" -path "*/tests/*" -type f | sort)
            TOTAL_FILES=${#TEST_FILES[@]}
            
            if [[ $TOTAL_FILES -eq 0 ]]; then
              echo "❌ No test files found!"
              find . -name "*test*.py" | head -5
              exit 1
            fi
            
            echo "Found $TOTAL_FILES test files, splitting into 4 shards"
            
            # Calcul des indices pour ce shard
            SHARD_SIZE=$(( (TOTAL_FILES + 3) / 4 ))  # arrondi supérieur
            START_IDX=$(( ((${{ matrix.shard }} - 1) * SHARD_SIZE) ))
            END_IDX=$(( START_IDX + SHARD_SIZE ))
            
            echo "Shard ${{ matrix.shard }}: files $START_IDX to $((END_IDX-1))"
            
            # Extraire les fichiers pour ce shard
            SHARD_FILES=()
            for (( i=START_IDX; i<END_IDX && i<TOTAL_FILES; i++ )); do
              SHARD_FILES+=("${TEST_FILES[i]}")
            done
            
            if [[ ${#SHARD_FILES[@]} -eq 0 ]]; then
              echo "⚠️ No test files assigned to shard ${{ matrix.shard }}"
              echo "Creating empty coverage file..."
              echo "# Empty shard - no tests assigned" > "$COVERAGE_FILE"
              TESTS_RAN=false
            else
              echo "Running ${#SHARD_FILES[@]} test files in this shard:"
              printf '  %s\n' "${SHARD_FILES[@]}"
              
              pytest "${SHARD_FILES[@]}" -m "unit" -n auto \
                --cov=server/app --cov-config=.coveragerc \
                --cov-report=term-missing \
                --cov-fail-under=0 --maxfail=1
              
              TESTS_RAN=true
            fi
          fi
          
          echo ""
          echo "=== POST-TEST STATUS ==="
          echo "Tests ran: $TESTS_RAN"
          echo "Current directory files:"
          ls -la .coverage* || echo "No .coverage* files found"

      - name: Normalize coverage filename (shard)
        run: |
          set -euxo pipefail
          TGT=".coverage.unit.${{ matrix.shard }}"
          echo "=== COVERAGE NORMALIZATION ==="
          echo "Target filename: $TGT"
          ls -la
          find . -maxdepth 1 -name ".coverage*" -ls || true
          if [[ -f "$TGT" ]]; then
            echo "✓ Target file already exists: $TGT"
          elif [[ -f ".coverage" ]]; then
            echo "→ Renaming .coverage to $TGT"
            mv .coverage "$TGT"
          else
            echo "# Placeholder - no coverage data" > "$TGT"
          fi
          # Nettoyage et permissions
          rm -f .coverage || true
          chmod 644 "$TGT"
          ls -la "$TGT"
            
      - name: Verify coverage file exists before upload
        run: |
          echo "=== PRE-UPLOAD VERIFICATION ==="
          echo "Checking for .coverage.unit.${{ matrix.shard }}"
          ls -l ".coverage.unit.${{ matrix.shard }}" || echo "❌ Not found in current dir"
          echo "Current dir: $(pwd)"
          echo "Workspace: ${{ github.workspace }}"
          find "${{ github.workspace }}" -name ".coverage.unit.${{ matrix.shard }}" -ls || echo "❌ Not found in workspace" 

      - name: Debug workspace avant upload
        run: |
          echo "=== DEBUG AVANT UPLOAD ==="
          echo "Current directory: $(pwd)"
          echo "GitHub workspace: ${{ github.workspace }}"
          echo "Matrix shard: ${{ matrix.shard }}"
          echo ""
          echo "Listing all coverage files:"
          find . -name ".coverage*" -ls 2>/dev/null || echo "No coverage files found in current dir"
          echo ""
          echo "Listing from GitHub workspace root:"
          find "${{ github.workspace }}" -name ".coverage.unit.${{ matrix.shard }}" -ls 2>/dev/null || echo "Not found in workspace root"
          echo ""
          echo "File existence check:"
          ls -la ".coverage.unit.${{ matrix.shard }}" 2>/dev/null || echo "File does not exist in current dir"
          echo ""
          echo "Environment variables:"
          env | grep -E "(WORKFLOW|WORKSPACE|GITHUB)" | head -10

      - name: Prepare for upload
        run: |
          mkdir -p artifacts
          cp .coverage.unit.${{ matrix.shard }} artifacts/coverage_unit_${{ matrix.shard }}
          
      - name: Upload raw coverage (shard ${{ matrix.shard }})
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-shard-${{ matrix.shard }}
          path: artifacts/coverage_unit_${{ matrix.shard }}
          retention-days: 1
          if-no-files-found: error
        
      - name: Debug après échec upload
        if: failure()
        run: |
          echo "=== DEBUG APRÈS ÉCHEC UPLOAD ==="
          echo "Vérification finale de l'existence du fichier:"
          find . -name "coverage_unit_${{ matrix.shard }}" -exec ls -la {} \; 2>/dev/null || echo "Fichier introuvable"
          echo ""
          echo "Arborescence complète du workspace:"
          pwd
          ls -la
          echo ""
          echo "Processus en cours:"
          ps auxf
        
  # ---------------------------------------------------------------------------
  # 1.bis) AGGREGATE — combine la couverture des 4 shards unit en un report
  # ---------------------------------------------------------------------------
  aggregate-unit-coverage:
    runs-on: ubuntu-latest
    needs: unit            # attend que les 4 shards aient fini
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install coverage tool
        run: pip install coverage

      - name: Create coverage directory
        run: mkdir -p coverage-files

      # Télécharger tous les artifacts de couverture
      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-shard-*
          path: coverage-files/
          merge-multiple: true

      - name: Debug downloaded files
        run: |
          echo "=== DOWNLOADED ARTIFACTS DEBUG ==="
          echo "Coverage files directory structure:"
          find coverage-files -type f -ls 2>/dev/null || true
          echo ""
          echo "Specifically looking for .coverage* files:"
          find coverage-files -name ".coverage*" -ls 2>/dev/null || true
          echo ""
          echo "All files in coverage-files:"
          find coverage-files -type f -exec ls -lh {} \; 2>/dev/null || true

      - name: Validate and combine coverage
        run: |
          set -euo pipefail
          
          echo "=== COVERAGE COMBINATION PROCESS ==="
          
          # Recherche flexible des fichiers de couverture
          mapfile -t all_files < <(find coverage-files -type f \( -name '.coverage*' -o -name 'coverage-*' \) 2>/dev/null || true)
          
          echo "Found ${#all_files[@]} coverage-related files total"
          
          # Filtrer les fichiers non vides et valides
          valid_files=()
          for file in "${all_files[@]}"; do
            if [[ -s "$file" ]]; then
              # Vérifier que ce n'est pas juste un placeholder
              if grep -q "# Placeholder\|# Empty" "$file" 2>/dev/null; then
                echo "  → Skipping placeholder: $(basename "$file")"
              else
                valid_files+=("$file")
                echo "  → Valid: $(basename "$file") ($(wc -l < "$file" 2>/dev/null || echo "?") lines)"
              fi
            else
              echo "  → Empty: $(basename "$file")"
            fi
          done
          
          echo ""
          echo "Found ${#valid_files[@]} valid coverage files"
          
          if [[ ${#valid_files[@]} -eq 0 ]]; then
            echo "⚠️ WARNING: No valid coverage files found!"
            echo "This could mean:"
            echo "  1. All shards had no tests to run"
            echo "  2. Coverage collection failed everywhere"
            echo "  3. All tests were skipped"
            echo ""
            echo "Creating minimal coverage report..."
            
            # Créer un rapport vide mais valide
            coverage erase || true
            coverage report --show-missing || echo "No data to report"
            coverage xml -o coverage-unit.xml || touch coverage-unit.xml
            coverage html -d htmlcov-unit || mkdir -p htmlcov-unit
            
            echo "✓ Empty coverage reports created"
          else
            echo "Combining ${#valid_files[@]} coverage files..."
            
            # Debug avant combination
            for file in "${valid_files[@]}"; do
              echo "Processing: $file"
              head -5 "$file" 2>/dev/null || echo "Cannot read file header"
            done
            
            coverage combine "${valid_files[@]}"
            
            echo ""
            echo "Generating comprehensive reports..."
            coverage report -m --skip-covered
            coverage xml -o coverage-unit.xml
            coverage html -d htmlcov-unit
            
            echo "✓ Coverage combination completed successfully"
            echo "Reports generated:"
            ls -lh coverage-unit.xml htmlcov-unit/ 2>/dev/null || true
          fi

      - name: Upload combined coverage XML
        uses: actions/upload-artifact@v4
        with:
          name: coverage-unit-xml
          path: coverage-unit.xml

      - name: Upload HTML report (unit)
        uses: actions/upload-artifact@v4
        with:
          name: htmlcov-unit
          path: htmlcov-unit/

  # ---------------------------------------------------------------------------
  # 2) INTEGRATION — stack Docker + migrations + tests host (séquentiel)
  # ---------------------------------------------------------------------------
  integration:
    runs-on: ubuntu-latest
    env:
      STUB_SLACK: "1"
      ALERT_REMINDER_MINUTES: "1"
      KEY: dev-apikey-123
      API: http://localhost:8000
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show Docker versions
        run: |
          docker --version
          docker compose version || true

      - name: Ensure curl + jq are present
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl jq

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install project deps (integration)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install "psycopg[binary]>=3.1,<4.0"

      - name: Prepare root .env.docker from example
        run: |
          if [ -f .env.example ]; then
            cp .env.example .env.docker
          else
            echo "ERROR: .env.example is missing at repo root" >&2
            exit 1
          fi
          awk 'BEGIN{pslack=0; prem=0}
               /^SLACK_WEBHOOK=/ {print "SLACK_WEBHOOK=http://httpbin:80/status/204"; pslack=1; next}
               /^ALERT_REMINDER_MINUTES=/ {print "ALERT_REMINDER_MINUTES=1"; prem=1; next}
               {print}
               END{
                 if(!pslack) print "SLACK_WEBHOOK=http://httpbin:80/status/204";
                 if(!prem)   print "ALERT_REMINDER_MINUTES=1";
                 print "STUB_SLACK=1";
               }' .env.docker > .env.ci && mv .env.ci .env.docker
          cp .env.docker docker/.env.docker
          sed 's/SLACK_WEBHOOK=.*/SLACK_WEBHOOK=[REDACTED]/' .env.docker

      - name: Start stack (db/redis/api/worker)
        working-directory: docker
        run: docker compose --env-file ../.env.docker up -d --build db redis api worker

      - name: Wait for DB
        working-directory: docker
        run: |
          echo "=== Waiting for database ==="
          for i in {1..60}; do
            echo "Attempt $i/60..."
            if docker compose --env-file ../.env.docker exec -T db pg_isready -U postgres; then
              echo "✓ Database is ready"
              break
            fi
            if [[ $i -eq 60 ]]; then
              echo "❌ Database failed to start"
              docker compose logs db
              exit 1
            fi
            sleep 2
          done

      - name: Run Alembic migrations
        working-directory: docker
        run: |
          echo "=== Running database migrations ==="
          docker compose --env-file ../.env.docker run --rm -w /app/server api alembic -c /app/server/alembic.ini upgrade head

      - name: Wait for API
        run: |
          echo "=== Waiting for API health check ==="
          for i in {1..60}; do
            echo "Attempt $i/60: checking $API/api/v1/health"
            if curl -fsS -m 2 -H "X-API-Key: $KEY" "$API/api/v1/health"; then
              echo "✓ API is healthy"
              exit 0
            fi
            if [[ $i -eq 60 ]]; then
              echo "❌ API health check failed"
              echo "=== API logs ==="
              docker compose -f docker/docker-compose.yml logs api | tail -50
              exit 1
            fi
            sleep 2
          done

      - name: Sanity env for DB (integration)
        env:
          PYTHONPATH: server
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          echo "=== Integration DB sanity check ==="
          echo "DATABASE_URL=$DATABASE_URL"
          python - <<'PY'
          import os
          print("ENV DATABASE_URL =", os.getenv("DATABASE_URL"))
          from app.core.config import settings
          print("settings.DATABASE_URL =", settings.DATABASE_URL)
          PY

      - name: Run integration tests (host)
        env:
          PYTHONPATH: server
          API: ${{ env.API }}
          KEY: ${{ env.KEY }}
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          echo "=== Running integration tests ==="
          pytest -m "integration" --no-cov --maxfail=1 -v

      - name: Dump docker logs on failure
        if: failure()
        working-directory: docker
        run: |
          echo "=== Container status ==="
          docker compose ps || true
          echo ""
          echo "=== API logs (last 400 lines) ==="
          docker compose logs api | tail -n 400 || true
          echo ""
          echo "=== Worker logs (last 400 lines) ==="
          docker compose logs worker | tail -n 400 || true
          echo ""
          echo "=== DB logs (last 200 lines) ==="
          docker compose logs db | tail -n 200 || true

      - name: Stop stack
        if: always()
        working-directory: docker
        run: docker compose --env-file ../.env.docker down -v

  # ---------------------------------------------------------------------------
  # 3) E2E — redémarre la stack minimale et lance les tests end-to-end
  # ---------------------------------------------------------------------------
  e2e:
    runs-on: ubuntu-latest
    env:
      STUB_SLACK: "1"
      ALERT_REMINDER_MINUTES: "1"
      KEY: dev-apikey-123
      API: http://localhost:8000
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show Docker versions
        run: |
          docker --version
          docker compose version || true

      - name: Ensure curl + jq are present
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl jq

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install project deps (e2e)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install "psycopg[binary]>=3.1,<4.0"

      - name: Prepare root .env.docker from example
        run: |
          if [ -f .env.example ]; then
            cp .env.example .env.docker
          else
            echo "ERROR: .env.example is missing at repo root" >&2
            exit 1
          fi
          awk 'BEGIN{pslack=0; prem=0}
               /^SLACK_WEBHOOK=/ {print "SLACK_WEBHOOK=http://httpbin:80/status/204"; pslack=1; next}
               /^ALERT_REMINDER_MINUTES=/ {print "ALERT_REMINDER_MINUTES=1"; prem=1; next}
               {print}
               END{
                 if(!pslack) print "SLACK_WEBHOOK=http://httpbin:80/status/204";
                 if(!prem)   print "ALERT_REMINDER_MINUTES=1";
                 print "STUB_SLACK=1";
               }' .env.docker > .env.ci && mv .env.ci .env.docker
          cp .env.docker docker/.env.docker
          sed 's/SLACK_WEBHOOK=.*/SLACK_WEBHOOK=[REDACTED]/' .env.docker

      - name: Start stack (db/redis/api)
        working-directory: docker
        run: docker compose --env-file ../.env.docker up -d --build db redis api

      - name: Wait for DB
        working-directory: docker
        run: |
          echo "=== Waiting for database ==="
          for i in {1..60}; do
            echo "Attempt $i/60..."
            if docker compose --env-file ../.env.docker exec -T db pg_isready -U postgres; then
              echo "✓ Database is ready"
              break
            fi
            if [[ $i -eq 60 ]]; then
              echo "❌ Database failed to start"
              docker compose logs db
              exit 1
            fi
            sleep 2
          done

      - name: Run Alembic migrations
        working-directory: docker
        run: |
          echo "=== Running database migrations ==="
          docker compose --env-file ../.env.docker run --rm -w /app/server api alembic -c /app/server/alembic.ini upgrade head

      - name: Wait for API to be healthy
        run: |
          echo "=== Waiting for API health check ==="
          for i in {1..60}; do
            echo "Attempt $i/60: checking $API/api/v1/health"
            if curl -fsS -m 2 -H "X-API-Key: $KEY" "$API/api/v1/health"; then
              echo "✓ API is healthy"
              exit 0
            fi
            if [[ $i -eq 60 ]]; then
              echo "❌ API health check failed"
              echo "=== API logs ==="
              docker compose -f docker/docker-compose.yml logs api | tail -50
              exit 1
            fi
            sleep 2
          done

      - name: Sanity env for DB (e2e)
        env:
          PYTHONPATH: server
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          echo "=== E2E DB sanity check ==="
          echo "DATABASE_URL=$DATABASE_URL"
          python - <<'PY'
          import os
          print("ENV DATABASE_URL =", os.getenv("DATABASE_URL"))
          from app.core.config import settings
          print("settings.DATABASE_URL =", settings.DATABASE_URL)
          PY

      - name: HTTP targets smoke
        env:
          API: ${{ env.API }}
          KEY: ${{ env.KEY }}
        run: |
          echo "=== Running HTTP targets smoke test ==="
          bash scripts/smoke_http_targets.sh

      - name: Run E2E tests
        env:
          PYTHONPATH: server
          API: ${{ env.API }}
          KEY: ${{ env.KEY }}
          STUB_SLACK: "1"
          ALERT_REMINDER_MINUTES: "1"
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          echo "=== Running E2E tests ==="
          # E2E : pas de parallélisme xdist (fragile sur stack partagée)
          pytest -m "e2e" --no-cov --maxfail=1 -v

      - name: Dump docker logs on failure
        if: failure()
        working-directory: docker
        run: |
          echo "=== Container status ==="
          docker compose ps || true
          echo ""
          echo "=== API logs (last 400 lines) ==="
          docker compose logs api | tail -n 400 || true
          echo ""
          echo "=== DB logs (last 200 lines) ==="
          docker compose logs db | tail -n 200 || true

      - name: Stop stack
        if: always()
        working-directory: docker
        run: docker compose --env-file ../.env.docker down -v