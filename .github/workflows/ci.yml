# CI en 3 étapes principales : unit → integration → e2e
# + 1 job "aggregate-unit-coverage" pour combiner la couverture des shards unit
# - Unit : parallélisé (matrix sharding x4 + xdist), DB SQLite in-memory
# - Integration / E2E : stack Docker, migrations Alembic, tests exécutés côté host
# - Pas d'upload Codecov (pas de compte requis). La couverture unit combinée est publiée en artifact.

name: CI

on:
  push:
    branches: [ main ]
  pull_request:

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  # ---------------------------------------------------------------------------
  # 1) UNIT — sans Docker, parallélisé par sharding (4 shards) + xdist
  # ---------------------------------------------------------------------------
  unit:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false         # ne stoppe pas les autres shards si un échoue
      matrix:
        shard: [1, 2, 3, 4]    # 4 shards équilibrés via pytest-split
    env:
      PYTHONPATH: server
      ENV_FILE: /dev/null
      DATABASE_URL: 'sqlite+pysqlite:///:memory:'
      REDIS_URL: redis://localhost:6379/0
      STUB_SLACK: "1"
      ALERT_REMINDER_MINUTES: "1"
      KEY: dev-apikey-123
      API: http://localhost:8000
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure curl + jq are present
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl jq

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install project deps (unit)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          # lib pour sharder proprement la suite (équilibrage par historique)
          pip install pytest-split

      # Debug après checkout et avec PYTHONPATH=server, comme demandé
      - name: Debug env & settings (after checkout)
        env:
          PYTHONPATH: server
        run: |
          echo "PYTHONPATH=${PYTHONPATH}"
          echo "ENV_FILE=${ENV_FILE}"
          echo "DATABASE_URL=${DATABASE_URL}"
          python - <<'PY'
          import os, sys
          print("ENV_FILE      =", os.getenv("ENV_FILE"))
          print("DATABASE_URL  =", os.getenv("DATABASE_URL"))
          print("sys.path[:3]  =", sys.path[:3])
          try:
              from app.core.config import settings
              print("settings.DATABASE_URL =", getattr(settings, "DATABASE_URL", None) or getattr(settings, "database_url", None))
          except Exception as e:
              print("Import settings FAILED:", e)
          PY

      - name: Run unit tests (shard ${{ matrix.shard }})
        env:
          CELERY_TASK_ALWAYS_EAGER: "1"
          STUB_SLACK: "1"
          ALERT_REMINDER_MINUTES: "1"
          SLACK_WEBHOOK: "http://httpbin:80/status/204"
          PYTHONPATH: server
        run: |
          # Chaque shard écrit un fragment de couverture distinct
          export COVERAGE_FILE=".coverage.unit.${{ matrix.shard }}"
          # Sharding: 4 groupes, ce runner exécute le groupe n
          # xdist: parallélisme intra-runner (CPU cores)
          pytest -m "unit" --splits 4 --group ${{ matrix.shard }} -n auto \
            --cov=server/app --cov-config=.coveragerc \
            --cov-report=term-missing \
            --cov-fail-under=0 --maxfail=1

      - name: Normalize coverage filename (shard)
        run: |
          set -euxo pipefail
          TGT=".coverage.unit.${{ matrix.shard }}"
          echo "Looking for coverage file for shard ${{ matrix.shard }}"
          echo "Current directory contents:"
          ls -la || true
          echo "Looking for any .coverage* files:"
          ls -la .coverage* || echo "No .coverage* files found"
          
          if [[ -f "$TGT" ]]; then
            echo "Found $TGT"
            ls -la "$TGT"
          elif [[ -f ".coverage" ]]; then
            mv .coverage "$TGT"
            echo "Moved .coverage -> $TGT"
            ls -la "$TGT"
          else
            echo "WARNING: no coverage data file produced for this shard"
            echo "This could indicate:"
            echo "1. No tests were run (empty shard)"
            echo "2. pytest/coverage failed"
            echo "3. Tests ran but no code was covered"
            # Créer un fichier vide pour éviter les erreurs d'upload
            : > "$TGT"
            echo "Created empty placeholder: $TGT"
          fi
          
          echo "Final coverage files:"
          ls -la .coverage* || true

      # CORRECTION: Chaque shard upload son propre artifact avec un nom unique
      - name: Upload raw coverage (shard ${{ matrix.shard }})
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-coverage-${{ matrix.shard }}
          path: .coverage.unit.${{ matrix.shard }}

  # ---------------------------------------------------------------------------
  # 1.bis) AGGREGATE — combine la couverture des 4 shards unit en un report
  # ---------------------------------------------------------------------------
  aggregate-unit-coverage:
    runs-on: ubuntu-latest
    needs: unit            # attend que les 4 shards aient fini
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install coverage tool
        run: pip install coverage

      # CORRECTION: Télécharger chaque shard individuellement
      - name: Download shard coverage 1
        uses: actions/download-artifact@v4
        with:
          name: unit-coverage-1
          path: coverage-files

      - name: Download shard coverage 2
        uses: actions/download-artifact@v4
        with:
          name: unit-coverage-2
          path: coverage-files

      - name: Download shard coverage 3
        uses: actions/download-artifact@v4
        with:
          name: unit-coverage-3
          path: coverage-files

      - name: Download shard coverage 4
        uses: actions/download-artifact@v4
        with:
          name: unit-coverage-4
          path: coverage-files

      - name: Debug downloaded files
        run: |
          echo "Downloaded files:"
          find coverage-files -type f -ls || true
          echo "Coverage files specifically:"
          find coverage-files -name ".coverage*" -ls || true

      - name: Combine + report (unit)
        run: |
          set -euo pipefail
          
          # Récupère tous les fichiers .coverage* non vides
          mapfile -t files < <(find coverage-files -type f -name '.coverage*' -size +0c)
          if [[ ${#files[@]} -eq 0 ]]; then
            echo "ERROR: No non-empty unit coverage files downloaded. Check shard jobs."
            exit 1
          fi
          
          echo "Combining coverage files: ${files[*]}"
          coverage combine "${files[@]}"
          coverage report -m
          coverage xml -o coverage-unit.xml
          coverage html -d htmlcov-unit

      - name: Upload combined coverage XML
        uses: actions/upload-artifact@v4
        with:
          name: coverage-unit-xml
          path: coverage-unit.xml

      - name: Upload HTML report (unit)
        uses: actions/upload-artifact@v4
        with:
          name: htmlcov-unit
          path: htmlcov-unit

  # ---------------------------------------------------------------------------
  # 2) INTEGRATION — stack Docker + migrations + tests host (séquentiel)
  # ---------------------------------------------------------------------------
  integration:
    runs-on: ubuntu-latest
    needs: aggregate-unit-coverage
    env:
      STUB_SLACK: "1"
      ALERT_REMINDER_MINUTES: "1"
      KEY: dev-apikey-123
      API: http://localhost:8000
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show Docker versions
        run: |
          docker --version
          docker compose version || true

      - name: Ensure curl + jq are present
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl jq

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install project deps (integration)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install "psycopg[binary]>=3.1,<4.0"

      - name: Prepare root .env.docker from example
        run: |
          if [ -f .env.example ]; then
            cp .env.example .env.docker
          else
            echo "ERROR: .env.example is missing at repo root" >&2
            exit 1
          fi
          awk 'BEGIN{pslack=0; prem=0}
               /^SLACK_WEBHOOK=/ {print "SLACK_WEBHOOK=http://httpbin:80/status/204"; pslack=1; next}
               /^ALERT_REMINDER_MINUTES=/ {print "ALERT_REMINDER_MINUTES=1"; prem=1; next}
               {print}
               END{
                 if(!pslack) print "SLACK_WEBHOOK=http://httpbin:80/status/204";
                 if(!prem)   print "ALERT_REMINDER_MINUTES=1";
                 print "STUB_SLACK=1";
               }' .env.docker > .env.ci && mv .env.ci .env.docker
          cp .env.docker docker/.env.docker
          sed 's/SLACK_WEBHOOK=.*/SLACK_WEBHOOK=[REDACTED]/' .env.docker

      - name: Start stack (db/redis/api/worker)
        working-directory: docker
        run: docker compose --env-file ../.env.docker up -d --build db redis api worker

      - name: Wait for DB
        working-directory: docker
        run: |
          for i in {1..60}; do
            docker compose --env-file ../.env.docker exec -T db pg_isready -U postgres && break
            sleep 2
          done

      - name: Run Alembic migrations
        working-directory: docker
        run: docker compose --env-file ../.env.docker run --rm -w /app/server api alembic -c /app/server/alembic.ini upgrade head

      - name: Wait for API
        run: |
          for i in {1..60}; do
            curl -fsS -m 2 -H "X-API-Key: $KEY" "$API/api/v1/health" && exit 0
            sleep 2
          done
          exit 1

      - name: Sanity env for DB (integration)
        env:
          PYTHONPATH: server
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          echo "DATABASE_URL=$DATABASE_URL"
          python - <<'PY'
          import os
          print("ENV DATABASE_URL =", os.getenv("DATABASE_URL"))
          from app.core.config import settings
          print("settings.DATABASE_URL =", settings.DATABASE_URL)
          PY

      - name: Run integration tests (host)
        env:
          PYTHONPATH: server
          API: ${{ env.API }}
          KEY: ${{ env.KEY }}
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          pytest -m "integration" --no-cov --maxfail=1

      - name: Dump docker logs on failure
        if: failure()
        working-directory: docker
        run: |
          docker compose ps || true
          docker compose logs api | tail -n 400 || true
          docker compose logs worker | tail -n 400 || true
          docker compose logs db | tail -n 200 || true

      - name: Stop stack
        if: always()
        working-directory: docker
        run: docker compose --env-file ../.env.docker down -v

  # ---------------------------------------------------------------------------
  # 3) E2E — redémarre la stack minimale et lance les tests end-to-end
  # ---------------------------------------------------------------------------
  e2e:
    runs-on: ubuntu-latest
    needs: integration
    env:
      STUB_SLACK: "1"
      ALERT_REMINDER_MINUTES: "1"
      KEY: dev-apikey-123
      API: http://localhost:8000
      PGOPTIONS: "-c lock_timeout=5s -c statement_timeout=60000"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show Docker versions
        run: |
          docker --version
          docker compose version || true

      - name: Ensure curl + jq are present
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl jq

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install project deps (e2e)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install "psycopg[binary]>=3.1,<4.0"

      - name: Prepare root .env.docker from example
        run: |
          if [ -f .env.example ]; then
            cp .env.example .env.docker
          else
            echo "ERROR: .env.example is missing at repo root" >&2
            exit 1
          fi
          awk 'BEGIN{pslack=0; prem=0}
               /^SLACK_WEBHOOK=/ {print "SLACK_WEBHOOK=http://httpbin:80/status/204"; pslack=1; next}
               /^ALERT_REMINDER_MINUTES=/ {print "ALERT_REMINDER_MINUTES=1"; prem=1; next}
               {print}
               END{
                 if(!pslack) print "SLACK_WEBHOOK=http://httpbin:80/status/204";
                 if(!prem)   print "ALERT_REMINDER_MINUTES=1";
                 print "STUB_SLACK=1";
               }' .env.docker > .env.ci && mv .env.ci .env.docker
          cp .env.docker docker/.env.docker
          sed 's/SLACK_WEBHOOK=.*/SLACK_WEBHOOK=[REDACTED]/' .env.docker

      - name: Start stack (db/redis/api)
        working-directory: docker
        run: docker compose --env-file ../.env.docker up -d --build db redis api

      - name: Wait for DB
        working-directory: docker
        run: |
          for i in {1..60}; do
            docker compose --env-file ../.env.docker exec -T db pg_isready -U postgres && break
            sleep 2
          done

      - name: Run Alembic migrations
        working-directory: docker
        run: docker compose --env-file ../.env.docker run --rm -w /app/server api alembic -c /app/server/alembic.ini upgrade head

      - name: Wait for API to be healthy
        run: |
          for i in {1..60}; do
            curl -fsS -m 2 -H "X-API-Key: $KEY" "$API/api/v1/health" && exit 0
            sleep 2
          done
          exit 1

      - name: Sanity env for DB (e2e)
        env:
          PYTHONPATH: server
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          echo "DATABASE_URL=$DATABASE_URL"
          python - <<'PY'
          import os
          print("ENV DATABASE_URL =", os.getenv("DATABASE_URL"))
          from app.core.config import settings
          print("settings.DATABASE_URL =", settings.DATABASE_URL)
          PY

      - name: HTTP targets smoke
        env:
          API: ${{ env.API }}
          KEY: ${{ env.KEY }}
        run: bash scripts/smoke_http_targets.sh

      - name: Run E2E tests
        env:
          PYTHONPATH: server
          API: ${{ env.API }}
          KEY: ${{ env.KEY }}
          STUB_SLACK: "1"
          ALERT_REMINDER_MINUTES: "1"
          DATABASE_URL: 'postgresql+psycopg://postgres:postgres@localhost:5432/monitoring?connect_timeout=5'
        run: |
          # E2E : pas de parallélisme xdist (fragile sur stack partagée)
          pytest -m "e2e" --no-cov --maxfail=1

      - name: Dump docker logs on failure
        if: failure()
        working-directory: docker
        run: |
          docker compose ps || true
          docker compose logs api | tail -n 400 || true
          docker compose logs db | tail -n 200 || true

      - name: Stop stack
        if: always()
        working-directory: docker
        run: docker compose --env-file ../.env.docker down -v